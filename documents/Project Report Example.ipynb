{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RLNN Tetris"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*by Federico Larrieu and Tyson O'Leary, May 5, 2023*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We both really enjoy Tetris and we are interested in applying reinforcement learning to a more complex problem than we've seen in class. Applying it to tetris will be constantly interesting, and the research we've done shows it also will not be trivial. \n",
    "\n",
    "For our project, we will create an AI to play Tetris. It will use a neural network and reinforcement learning to learn to play tetris optimally. This will require us to either find an implementation of Tetris or implement the game ourselves, then define our states and actions to be used by the Q-net. \n",
    "\n",
    "The questions we will seek to answer:\n",
    "  * What is the highest number of cleared lines our AI can reach?\n",
    "  * What is the highest score our AI can achieve?\n",
    "  * Can we split this problem into multiple neural networks to solve different parts of the problem?\n",
    "\n",
    "We hypothesize that copying the reinforcement learning methods we learned in class most likely will not produce satisfactory results. We plan to explore multiple definitions for the actions and states, as well as multiple architectures like an ensemble model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What, why, very brief overview of methods and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build off of the neural networks we have created in class to make our reinforced learning networks. We also already have an implementation of Tetris that we can use to test and present our networks, and possibly to train them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To approach creating an AI for Tetris we have decided to decompose Tetris into its different problems. The first of which is to decide the best placement for a piece. The second is how to move the piece into a specified position and rotation. We may also introduce new features, if time permits, such as piece selection strategy. Splitting the Tetris strategy into two different individual problems will allow to allocate the responsibility to two different reinforced neural networks. We will deploy both reinforced neural networks into an ensemble model architecture. The flow of the ensemble model architecture is as follows. First, a still frame of the game will be input, if a piece is held we will run both the piece held and the current piece through the position neural network. The position of the piece with the better placement will be output. If no piece is held, then the next piece and the current piece through the position neural network. The position of the piece with the better placement will be output. Next, the best position will be used in the input for the movement neural network, which will decide the next best action to move towards that position."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![EnsembleModel](EnsembleModel.drawio.svg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position Reinforced Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network that learns to find the best possible end position of a piece will take in all pixels of the board and the type of piece as input, and output the best landing position and rotation. Each training epoch, the network will try a possible position, and get a reward based on a few factors. This might include the height of the piece, whether it creates holes, and the number of lines it would clear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PositionRLNN](PositionRLNN.drawio.svg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PositionTraining](PositionTraining.drawio.svg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movement Reinforced Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps I took.  Resources I used, such as code from the class, on-line resources, research articles, books [Goodfellow, et al., 2016], ....\n",
    "\n",
    "REQUIRED: If this is a team project, clearly describe in detail what each team member did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all results.  Intermediate results might be shown in above Methods section.  Plots, tables, whatever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I learned.  What was difficult.  Changes I had to make to timeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Goodfellow, et al., 2016] Ian Goodfellow and Yoshua Bengio and Aaron Courville, [Deep Learning](http://www.deeplearningbook.org), MIT Press. 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Your report for a single person team should contain **approximately** 2,000 words times number of team members, in markdown cells.  You can count words by running the following python code in your report directory.  Projects with two people, for example, should contain about 4,000 words, a four-person team should submit a report of approximately 8,000 words.\n",
    "\n",
    "Of course, your results and analysis speak much more than the word count.  Deep analysis in a shorter form is better than vague, over-wordy non-analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count for file Project Report Example.ipynb is 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\signal\\miniconda3\\lib\\site-packages\\nbformat\\current.py:19: UserWarning: nbformat.current is deprecated.\n",
      "\n",
      "- use nbformat for read/write/validate public API\n",
      "- use nbformat.vX directly to composing notebooks of a particular version\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from nbformat import current\n",
    "import glob\n",
    "nbfile = glob.glob('Project Report Example.ipynb')\n",
    "if len(nbfile) > 1:\n",
    "    print('More than one ipynb file. Using the first one.  nbfile=', nbfile)\n",
    "with io.open(nbfile[0], 'r', encoding='utf-8') as f:\n",
    "    nb = current.read(f, 'json')\n",
    "word_count = 0\n",
    "for cell in nb.worksheets[0].cells:\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
    "print('Word count for file', nbfile[0], 'is', word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
